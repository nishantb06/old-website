<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Nishant Bhansali</title>
    <link>https://nishantb06.github.io/posts/</link>
    <description>Recent content in Posts on Nishant Bhansali</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 16 Oct 2022 00:06:25 +0530</lastBuildDate><atom:link href="https://nishantb06.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>TMUX for Machine Learning Engineers</title>
      <link>https://nishantb06.github.io/posts/tmux/</link>
      <pubDate>Sun, 16 Oct 2022 00:06:25 +0530</pubDate>
      
      <guid>https://nishantb06.github.io/posts/tmux/</guid>
      <description>What is Tmux TMUX (Terminal Multiplexer) is a program which helps create and manage various terminal sessions created from a terminal itself. We can detach these newly created terminal which helps in asyncronously running multiple programs.
These terminal will keep on executing a particular command in the background untill we explicitly stop it after attaching it to an active terminal session.
We can create multiple terminal sessions and view and manage them in the same window by toggling between them.</description>
    </item>
    
    <item>
      <title>Docker Cheatsheet</title>
      <link>https://nishantb06.github.io/posts/third/</link>
      <pubDate>Sun, 11 Sep 2022 10:15:51 +0530</pubDate>
      
      <guid>https://nishantb06.github.io/posts/third/</guid>
      <description>But it works on my machine !!?? The above sentence is exactly the problem docker solves -
Earlier there was no way to run 2 applications (different OS) on the same machine. VMware solved this problem by introducing Virtual Machines. But we would have to separately assign RAM and storage for our second machine. This was still a bottleneck as we can&amp;rsquo;t ship applications effectively with this, which is why Docker was invented.</description>
    </item>
    
    <item>
      <title>Mobile-VIT [Paper Summary]</title>
      <link>https://nishantb06.github.io/posts/second/</link>
      <pubDate>Fri, 09 Sep 2022 21:30:05 +0530</pubDate>
      
      <guid>https://nishantb06.github.io/posts/second/</guid>
      <description>Papers With Code
Observations Theres a global inductive bias in CNN’s (invariance to shift and scale) which is why CNN’s have comparable performance w.r.t Transformers (Reference to this statement is in the Transformer survey paper). Transformer models overcome this with the help of extensive training regimes, large datasets and larger models. (It will be good if we mention this in the paper somewhere) CoreML library was used to perform testing on I- phone 12 Good things about the paper the paper has two significant contributions A novel architecture which combines convolution block from MobileNetV2 and the self attention block.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://nishantb06.github.io/posts/sscd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nishantb06.github.io/posts/sscd/</guid>
      <description>A Self-Supervised Descriptor for Image Copy Detection - Review [Paper][Code]
They have built upon the work of SimCLR and successfully tackled its limitations. Do give this paper a read if you are looking for a way of generating powerful embeddings/descriptors for your image dataset.
Good things about the paper It Introduces regularisation term based on Entropy which is used to make the descriptors more sparse. Which means that negative images wont be as “close” to each other as they used to be in SimCLR.</description>
    </item>
    
  </channel>
</rss>
