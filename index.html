<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.122.0">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Nishant Bhansali</title>
  <meta name="description" content="Currently resolving CUDA out of memory error" />

  
  <link type="text/css" rel="stylesheet" href="https://nishantb06.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://nishantb06.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://nishantb06.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://nishantb06.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="https://nishantb06.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Nishant Bhansali" />
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://nishantb06.github.io/"><h1>Nishant Bhansali</h1></a>
      <p class="lead">
       Currently resolving CUDA out of memory error 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://nishantb06.github.io/">Home</a> </li>
        <li><a href="/about/"> About Me </a></li><li><a href="https://github.com/nishantb06/"> Github </a></li><li><a href="https://www.kaggle.com/nishantbhansali"> Kaggle </a></li><li><a href="https://www.linkedin.com/in/nishantbhansali/"> LinkedIn </a></li><li><a href="/resume/"> Portfolio </a></li><li><a href="https://twitter.com/itsnishant14"> Twitter </a></li>
      </ul>
    </nav>

    <p>&copy; 2024. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="posts">
<article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/quantisation/">Quantisation Notes</a>
  </h1>
  <time datetime="2024-05-07T19:38:20&#43;0530" class="post-date">Tue, May 7, 2024</time>
  Lie mao blog very detailed with code https://iq.opengenus.org/basics-of-quantization-in-ml/ See for code for activation aware quantization Hugging face quantisation [Pytorch quantisation api docs]
There are 4 methods to optimise a model, GPTQ, activation aware quantized training, bits and bytes , packages like huggingfuace optimum, or pytorch api itself.
Scripting the model can make inference faster for a few reasons:
Reduced Overhead: Scripted models can have lower overhead compared to their original Python counterparts because the script represents a more optimized version of the model&rsquo;s forward pass.
  
  <div class="read-more-link">
    <a href="/posts/quantisation/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/distributed_training/">Distributed training Notes</a>
  </h1>
  <time datetime="2024-05-07T19:37:39&#43;0530" class="post-date">Tue, May 7, 2024</time>
  Data Parrallel Each GPU holds the full copy of the model Each GPU/Process/worker gets a different copy of the data to train on After each backword pass the master node will average out the model parameters . this averaged model will be shared between the workers again.
Distributed Data Parrallel after a forward pass, gradients are calculated for each worker and the master node then averages out the gradients , calculates the new model weights and shares these with the workers.
  
  <div class="read-more-link">
    <a href="/posts/distributed_training/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/resume/">Portfolio</a>
  </h1>
  <time datetime="2024-05-04T21:25:02&#43;0100" class="post-date">Sat, May 4, 2024</time>
  Hi, after my extensive work on Content Moderation Systems at Sharechat, I consider myself a generalist who can train, finetune, deploy Deep Learning Models across different modalites (Vision, NLP, Audio) in scalable production environments. My everyday work has included everything from Microsoft Excel to Kubernetes and working together with folks from Product, Operation, Data Scientists and Engineers alike. With a base in Computer Vision, I have a thorough understanding of how to train/finetune LLM&rsquo;s and how to build RAG applications with them as well.
  
  <div class="read-more-link">
    <a href="/resume/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/torchserve/">Deploying Models at Scale using Torchserve</a>
  </h1>
  <time datetime="2024-03-31T23:39:16&#43;0530" class="post-date">Sun, Mar 31, 2024</time>
  AI Shit
TorchServe is a flexible and easy to use tool for serving PyTorch machine learning (ML) models at scale. It is part of the PyTorch ecosystem and was developed in collaboration with AWS to facilitate the deployment of PyTorch models in production environments.
TorchServe simplifies the process of deploying PyTorch models by providing a straightforward and standardized way to package and serve them. It supports multiple types of models, including those for image and text classification, object detection, and more.
  
  <div class="read-more-link">
    <a href="/posts/torchserve/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/go_bigquery/">Pushing New Rows to BigQuery Table in GCP using Go</a>
  </h1>
  <time datetime="2024-01-12T22:26:26&#43;0530" class="post-date">Fri, Jan 12, 2024</time>
  In this blog post, we&rsquo;ll explore how to push new rows into a BigQuery table using Go. BigQuery, a serverless and highly-scalable data warehouse, is a part of Google Cloud Platform (GCP). We will be using the cloud.google.com/go/bigquery package for Go to interact with BigQuery.
Introduction Prerequisites Before diving into the code, make sure you have the following set up:
A GCP project with BigQuery enabled Service account credentials in a JSON file Go installed on your machine Template package main import ( &#34;context&#34; &#34;fmt&#34; &#34;log&#34; &#34;time&#34; &#34;cloud.
  
  <div class="read-more-link">
    <a href="/posts/go_bigquery/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/dev_containers/">Dev Containers: Open Vscode editor inside any Docker image</a>
  </h1>
  <time datetime="2024-01-01T14:10:41&#43;0530" class="post-date">Mon, Jan 1, 2024</time>
  Let’s say you have a docker image for an application and you want to run some test or experiment/add some new feature to that application. Normally I would build that image locally and mount the application directory as volume when I run that container. But something better exists
Using Dev Containers is better because
It gives the VS code experience for any docker image. Different VS code extensions can be used here like Linting, Copilot etc.
  
  <div class="read-more-link">
    <a href="/posts/dev_containers/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/llama_alpaca/">The Annotated LLaMA</a>
  </h1>
  <time datetime="2023-04-15T13:34:45&#43;0530" class="post-date">Sat, Apr 15, 2023</time>
  Foreword Welcome to “The Annotated LLaMA”.
One of the most brilliant and well-explained articles I have read is The Annotated Transformer and the Annotated DETR. It introduced Attention like no other post. The simple idea was to present an “annotated” version of the paper Attention is all you need along with code.
I have tried to do something similar with the LLaMA models by Meta Research, without which the commercial use of many Large Language models would not have been possible.
  
  <div class="read-more-link">
    <a href="/posts/llama_alpaca/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/sscd/">A Self-Supervised Descriptor for Image Copy Detection - Review</a>
  </h1>
  <time datetime="2023-01-13T07:40:39&#43;0530" class="post-date">Fri, Jan 13, 2023</time>
  A Self-Supervised Descriptor for Image Copy Detection - Review [Paper][Code]
They have built upon the work of SimCLR and successfully tackled its limitations. Do give this paper a read if you are looking for a way of generating powerful embeddings/descriptors for your image dataset.
Good things about the paper It Introduces regularisation term based on Entropy which is used to make the descriptors more sparse. Which means that negative images wont be as “close” to each other as they used to be in SimCLR.
  
  <div class="read-more-link">
    <a href="/posts/sscd/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/tmux/">TMUX for Machine Learning Engineers</a>
  </h1>
  <time datetime="2022-10-16T00:06:25&#43;0530" class="post-date">Sun, Oct 16, 2022</time>
  What is Tmux TMUX (Terminal Multiplexer) is a program which helps create and manage various terminal sessions created from a terminal itself. We can detach these newly created terminal which helps in asyncronously running multiple programs.
These terminal will keep on executing a particular command in the background untill we explicitly stop it after attaching it to an active terminal session.
We can create multiple terminal sessions and view and manage them in the same window by toggling between them.
  
  <div class="read-more-link">
    <a href="/posts/tmux/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/third/">Docker Cheatsheet</a>
  </h1>
  <time datetime="2022-09-11T10:15:51&#43;0530" class="post-date">Sun, Sep 11, 2022</time>
  But it works on my machine !!?? The above sentence is exactly the problem docker solves -
Earlier there was no way to run 2 applications (different OS) on the same machine. VMware solved this problem by introducing Virtual Machines. But we would have to separately assign RAM and storage for our second machine. This was still a bottleneck as we can&rsquo;t ship applications effectively with this, which is why Docker was invented.
  
  <div class="read-more-link">
    <a href="/posts/third/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/posts/second/">Mobile-VIT [Paper Summary]</a>
  </h1>
  <time datetime="2022-09-09T21:30:05&#43;0530" class="post-date">Fri, Sep 9, 2022</time>
  Papers With Code
Observations Theres a global inductive bias in CNN’s (invariance to shift and scale) which is why CNN’s have comparable performance w.r.t Transformers (Reference to this statement is in the Transformer survey paper). Transformer models overcome this with the help of extensive training regimes, large datasets and larger models. (It will be good if we mention this in the paper somewhere) CoreML library was used to perform testing on I- phone 12 Good things about the paper the paper has two significant contributions A novel architecture which combines convolution block from MobileNetV2 and the self attention block.
  
  <div class="read-more-link">
    <a href="/posts/second/">Read More…</a>
  </div>
  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://nishantb06.github.io/about/">About Me</a>
  </h1>
  <time datetime="2021-10-31T21:25:02&#43;0100" class="post-date">Sun, Oct 31, 2021</time>
  Who am I? Hi, my name is Nishant Bhansali. I&rsquo;m working as a Machine Learning Engineer at Sharechat,working remotely from Ahmedabad,India. I have majorly worked on solving Computer Vision and Digital Image Processing based problems, ands thats where I would say my expertise lies. Be it recent transformer architectures or archaic Image processing algorithms, I have my my hands dirtied by almost everything vision based. My work at Sharechat has been around Image Enhancement and Image Quality assessement.
  
  <div class="read-more-link">
    <a href="/about/">Read More…</a>
  </div>
  
</article>
</div>
    </main>

    
      
    
  </body>
</html>
